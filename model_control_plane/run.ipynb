{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Model Control Plane Backend: A Practical Guide\n",
    "Welcome to our tour into the Model Control Plane, where we'll focus on two independent pipelines within ZenML. Each pipeline works on its own, creating specific artifacts. But what's fascinating is that these seemingly separate pipelines are intricately connected, all with the goal of delivering precise predictions.\n",
    "\n",
    "Before the Model Control Plane, connecting these pipelines and consolidating everything was a challenge. Imagine extracting a trained model artifact from the training pipeline and smoothly integrating it into the predictions pipeline. Previously, this involved complex ID references, leading to constant config updates, or blindly relying on the latest training run. But what if that run didn't meet the necessary performance standards? Using a subpar model for predictions was out of the question, especially for vital applications!\n",
    "\n",
    "Enter the Model Control Plane. This feature empowers you to effortlessly group pipelines, artifacts, and crucial business data into a unified entity: a `Model`. A Model captures lineage information and more. Within a Model, different `Model Versions` can be staged. For example, you can rely on your predictions at a specific stage, like `Production``, and decide whether the Model Version should be promoted based on your business rules during training. Plus, accessing data from other Models and their Versions is just as simple, enhancing the system's adaptability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on Colab\n",
    "\n",
    "You can use Google Colab to run this notebook, no signup / installation required!\n",
    "\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zenml-io//zenml-plugins/blob/main/model_control_plane/run.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the process\n",
    "\n",
    "![Pipelines Overview](_assets/train_prediction_example.png)\n",
    "\n",
    "Each time the `train_and_promote` pipeline runs, it creates a new iris_classifier. However, it only promotes the created model to `Production` if a certain accuracy threshold is met. The `do_predictions` pipeline simply picks up the latest Promoted model and runs batch inference on it. That way these two pipelines can independently be run, but can rely on each others output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.environment import Environment\n",
    "\n",
    "if Environment.in_google_colab():\n",
    "    # Install Cloudflare Tunnel binary\n",
    "    !wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb && dpkg -i cloudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"zenml[server,dev]>=0.45.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This might lead to a blocked cell, if its blocking just stop the notebook and skip this cell (server has been started)\n",
    "!zenml up --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning: This will remove all your local ZenML artifacts. If you don't want this then just remove the zenml clean command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml clean -y  # remove this if you dont want to lose local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install sklearn -y\n",
    "\n",
    "import IPython\n",
    "from zenml import show\n",
    "IPython.Application.instance().kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm -rf .zen\n",
    "!zenml init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training pipeline: Create models and model versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Training pipeline orchestrates the training of a model object, storing datasets and the model object itself as links within a newly created Model Version. This integration is achieved by configuring the pipeline within a Model Context using `ModelConfig`. The name and `create_new_model_version` fields are specified, while other fields remain optional for this task.\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!zenml model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml import get_step_context, step\n",
    "from zenml.enums import ModelStages\n",
    "from zenml.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "@step\n",
    "def promote_model(score: float):\n",
    "    logger.info(f\"The latest model score is: {score}\")\n",
    "    if score > 0.7:\n",
    "        logger.info(\"Passed quality control... Promoting.\")\n",
    "        model_config = get_step_context().model_config\n",
    "        model_version = model_config._get_model_version()\n",
    "        model_version.set_stage(ModelStages.PRODUCTION, force=True)\n",
    "    else:\n",
    "        logger.info(\"Latest model failed quality control. Not promoting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml import pipeline\n",
    "from zenml.model import ModelConfig\n",
    "\n",
    "from steps.train.load import load_data\n",
    "from steps.train.train import train_and_evaluate\n",
    "\n",
    "\n",
    "@pipeline(\n",
    "    enable_cache=False,\n",
    "    model_config=ModelConfig(\n",
    "        name=\"iris_classifier\",\n",
    "        license=\"Apache\",\n",
    "        description=\"Show case Model Control Plane.\",\n",
    "        create_new_model_version=True,\n",
    "        delete_new_version_on_failure=True,\n",
    "    ),\n",
    ")\n",
    "def train_and_promote_model():\n",
    "    train_data, test_data = load_data()\n",
    "    _, score = train_and_evaluate(train_data=train_data, test_data=test_data)\n",
    "    promote_model(score=score)\n",
    "\n",
    "\n",
    "train_and_promote_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the training pipeline creates a model and a Model Version, all while maintaining a connection to the artifacts.\n",
    "\n",
    "Once it's done, check the results to see the newly created entities:\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model `iris_classifier` created\n",
    "!zenml model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model version `1` created\n",
    "!zenml model version list iris_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list generic artifacts - train and test datasets are here\n",
    "!zenml model version artifacts iris_classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list model objects - trained classifier here\n",
    "!zenml model version model_objects iris_classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list deployments - none, as we didn't link any\n",
    "!zenml model version deployments iris_classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list runs - training run linked\n",
    "!zenml model version runs iris_classifier 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pipeline again and see new version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_promote_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model version `2` created and promoted to production\n",
    "!zenml model version list iris_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the results in the ZenML dashboard (This is a live session, you can come back to it anytime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions pipeline: Use the latest production model to infer results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions pipeline\n",
    "\n",
    "The Predictions Pipeline reads a trained model object from the Model Version labeled as Production. Here, the `version` is set to a specific stage, ensuring consistency across multiple runs. This approach shields the pipeline from the underlying complexities of the Training pipeline's promotion logic.\n",
    "\n",
    "Given the frequent execution of the predictions pipeline compared to the training pipeline, we link predictions as versioned artifacts. The `overwrite` flag in the artifact configuration controls this, allowing for a comprehensive historical view.\n",
    "\n",
    "\n",
    "Need to use a specific model version, not limited to stages? No problem. You can represent this either by version number or name, ensuring flexibility in your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml import get_pipeline_context, pipeline\n",
    "from zenml.artifacts.external_artifact import ExternalArtifact\n",
    "from zenml.enums import ModelStages\n",
    "from zenml.model import ModelConfig\n",
    "\n",
    "from steps.predict.load import load_data\n",
    "from steps.predict.predict import predict\n",
    "\n",
    "\n",
    "@pipeline(\n",
    "    enable_cache=False,\n",
    "    model_config=ModelConfig(\n",
    "        name=\"iris_classifier\",\n",
    "        version=ModelStages.PRODUCTION,\n",
    "    ),\n",
    "    extra={\"trained_classifier\": \"iris_classifier\"},\n",
    ")\n",
    "def do_predictions():\n",
    "    trained_classifier = get_pipeline_context().extra[\"trained_classifier\"]\n",
    "    inference_data = load_data()\n",
    "    predict(\n",
    "        model=ExternalArtifact(\n",
    "            model_artifact_name=trained_classifier\n",
    "        ),  # model_name and model_version derived from pipeline context\n",
    "        data=inference_data,\n",
    "    )\n",
    "\n",
    "\n",
    "do_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifacts Exchange Between Pipelines: Seamless Integration\n",
    "\n",
    "In this pipeline, artifacts linked during the training stage are passed on. Leveraging `ExternalArtifact`, we effortlessly pass previously linked artifacts without repeating the model name and version setup.\n",
    "\n",
    "*Handy Tip*: Explore further possibilities by using the `model_name` and `model_version` attributes of `ExternalArtifact` to pull artifacts from other models.\n",
    "\n",
    "```python\r\n",
    "from zenml.artifacts.external_artifact import ExternalArtifact\r\n",
    "\r\n",
    "@pipeline(\r\n",
    "    model_config=...,\r\n",
    "    extra={\"trained_classifier\": \"iris_classifier\"},\r\n",
    ")\r\n",
    "def do_predictions():\r\n",
    "    ...\r\n",
    "    predict(\r\n",
    "        model=ExternalArtifact(\r\n",
    "            model_artifact_name=trained_classifier\r\n",
    "        ),  # model_name and model_version derived from pipeline context\r\n",
    "        ...\r\n",
    "   \n",
    "\n",
    "Executing the prediction pipeline ensures the use of the Model Version in Production stage, generating predictions as versioned artifacts.\r\n",
    " )\r\n",
    "    ...\r\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml import pipeline\n",
    "from zenml.model import ModelConfig\n",
    "\n",
    "from steps.train.load import load_data\n",
    "from steps.train.promote import promote_model\n",
    "from steps.train.train import train_and_evaluate\n",
    "\n",
    "\n",
    "@pipeline(\n",
    "    enable_cache=False,\n",
    "    model_config=ModelConfig(\n",
    "        name=\"iris_classifier\",\n",
    "        license=\"Apache\",\n",
    "        description=\"Show case Model Control Plane.\",\n",
    "        create_new_model_version=True,\n",
    "        delete_new_version_on_failure=True,\n",
    "    ),\n",
    ")\n",
    "def train_and_promote_model():\n",
    "    train_data, test_data = load_data()\n",
    "    _, score = train_and_evaluate(train_data=train_data, test_data=test_data)\n",
    "    promote_model(score=score)\n",
    "\n",
    "train_and_promote_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no new model version created, just consuming existing model\n",
    "!zenml model version list iris_classifier\n",
    "\n",
    "# list train, test and inference datasets and predictions artifacts\n",
    "!zenml model version artifacts iris_classifier 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! By reusing the model version in the Production stage, you've connected the inference dataset and predictions seamlessly. All these elements coexist within the same model version, allowing effortless tracing back to training data and model metrics.\n",
    "\n",
    "And what if you run the prediction pipeline again?\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list train, test datasets and two version of \n",
    "# inference dataset and prediction artifacts\n",
    "!zenml model version artifacts iris_classifier 1\n",
    "\n",
    "# list runs, prediction runs are also here\n",
    "!zenml model version runs iris_classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml import show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything worked seamlessly! You've added two more links to your artifacts, representing new predictions and inference dataset versions. Later, this detailed history can aid analysis or retrieving predictions from specific dates. Additionally, the prediction pipeline runs are conveniently attached to the same model version, ensuring you always know which code interacted with your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Command-Line Features\n",
    "\n",
    "Explore additional CLI capabilities, like updating existing models and creating new ones, using straightforward commands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Updating Existing Models via CLI\n",
    "!zenml model update iris_classifier -t tag1 -t tag2 -e \"some ethical implications\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Creating a Model via CLI\n",
    "!zenml model register -n iris_classifier_cli -d \"created from cli\" -t cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Well done! Time for a Quick Cleanup\n",
    "\n",
    "!zenml model delete iris_classifier_cli\n",
    "!zenml model delete iris_classifier -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done, and now your workspace is tidy! Feel free to reach out if you have any more questions or if there's anything else you'd like to explore. Happy modeling! 😊"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
